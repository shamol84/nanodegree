{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Loading required package library\n",
    "\n",
    "import os, glob, math, cv2, time\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from joblib import Parallel, delayed\n",
    "import cPickle as pickle\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load folder c0\n",
      "Load folder c1\n",
      "Load folder c2\n",
      "Load folder c3\n",
      "Load folder c4\n",
      "Load folder c5\n",
      "Load folder c6\n",
      "Load folder c7\n",
      "Load folder c8\n",
      "Load folder c9\n"
     ]
    }
   ],
   "source": [
    "## image reading and appending to a list\n",
    "f =[]\n",
    "for j in range(10):\n",
    "    print('Load folder c{}'.format(j))\n",
    "    path = os.path.join('/home/mohammad/Downloads/imgs/train', 'c' + str(j)+'/*')\n",
    "    f.append(len(glob.glob(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## getting image class name from folder name\n",
    "c =[]\n",
    "for j in range(10):\n",
    "    c.append('c'+str(j))\n",
    "#f = zip(c,f)\n",
    "#c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Data Exploration ##\n",
    "## histogram plot to check distrbution\n",
    "import matplotlib.pyplot as plt\n",
    "#histogram=plt.figure()\n",
    "f = np.asarray(f)\n",
    "y_pos = np.arange(len(c))\n",
    "plt.bar(y_pos,f, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, c)\n",
    "plt.ylabel('Total number of pictures')\n",
    "plt.title('')\n",
    " \n",
    "#plt.show()\n",
    "plt.savefig('/home/mohammad/picture_hist.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load folder c0\n",
      "Load folder c1\n",
      "Time: 49.05 seconds\n"
     ]
    }
   ],
   "source": [
    "### image normalization and resizing in parallel\n",
    "### codes taken kaggle.com\n",
    "img_size = 50\n",
    "sz = (img_size, img_size)\n",
    "\n",
    "nprocs = 3 ## number of processors\n",
    "\n",
    "## image resize functions\n",
    "def resize_image(img_file):\n",
    "    img = cv2.imread(img_file,0)\n",
    "    img = cv2.resize(img, sz).astype('float32') / 255.0\n",
    "    return img\n",
    "\n",
    "start = time.time()\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "##loop image reading, and resizing using parallel processing\n",
    "for j in range(10):\n",
    "    print('Load folder c{}'.format(j))\n",
    "    path = os.path.join('/home/mohammad/Downloads/imgs/train', 'c' + str(j), '*.jpg')\n",
    "    files = glob.glob(path)\n",
    "    X_train.extend(Parallel(n_jobs=nprocs)(delayed(resize_image)(im_file) for im_file in files))\n",
    "    Y_train.extend([j]*len(files))\n",
    "    \n",
    "end = time.time() - start\n",
    "print(\"Time: %.2f seconds\" % end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load folder c0\n",
      "Load folder c1\n",
      "Load folder c2\n",
      "Load folder c3\n",
      "Load folder c4\n",
      "Load folder c5\n",
      "Load folder c6\n",
      "Load folder c7\n",
      "Load folder c8\n",
      "Load folder c9\n",
      "Time: 186.84 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### image normalization and resizing in parallel for rgb\n",
    "img_size = 50\n",
    "sz = (img_size, img_size)\n",
    "\n",
    "def process_image(img_file):\n",
    "    img = cv2.imread(img_file)\n",
    "    img = cv2.resize(img, sz).transpose((2,0,1)).astype('float32')\n",
    "    img[:,:,0] -= 103.939\n",
    "    img[:,:,1] -= 116.779\n",
    "    img[:,:,2] -= 123.68\n",
    "    return img\n",
    "\n",
    "\n",
    "nprocs = 3\n",
    "start = time.time()\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for j in range(10):\n",
    "    print('Load folder c{}'.format(j))\n",
    "    path = os.path.join('/home/mohammad/Downloads/imgs/train', 'c' + str(j), '*.jpg')\n",
    "    files = glob.glob(path)\n",
    "    X_train.extend(Parallel(n_jobs=nprocs)(delayed(process_image)(im_file) for im_file in files))\n",
    "    Y_train.extend([j]*len(files))\n",
    "    \n",
    "end = time.time() - start\n",
    "print(\"Time: %.2f seconds\" % end)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 3, 50, 50) (22424,)\n"
     ]
    }
   ],
   "source": [
    "##chekcing train and test shape\n",
    "x= np.array(X_train)\n",
    "y = np.array(Y_train)\n",
    "print x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##saving file\n",
    "f = open('/home/mohammad/img_data_rgb.p', 'wb')   \n",
    "pickle.dump(x, f)          \n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##saving file\n",
    "f = open('/home/mohammad/img_label_rgb.p', 'wb')  \n",
    "pickle.dump(y, f)          # dump data to f\n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## generating train, test and validation data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train1, y_train1, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for rgb\n",
    "img_size = 224\n",
    "sz = (img_size, img_size)\n",
    "\n",
    "def process_image(img_file):\n",
    "    img = io.imread(img_file)    \n",
    "    img = resize(img, sz,mode='nearest').transpose((2,0,1)).astype('float32')\n",
    "    img[:,:,0] -= 103.939\n",
    "    img[:,:,1] -= 116.779\n",
    "    img[:,:,2] -= 123.68\n",
    "    return img\n",
    "\n",
    "\n",
    "nprocs = 3\n",
    "start = time.time()\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "np.arange(6,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load folder c6\n",
      "Load folder c7\n",
      "Time: 72.24 seconds\n"
     ]
    }
   ],
   "source": [
    "for j in np.arange(6,8):\n",
    "    print('Load folder c{}'.format(j))\n",
    "    path = os.path.join('/home/mohammad/Downloads/imgs/train', 'c' + str(j), '*.jpg')\n",
    "    files = glob.glob(path)\n",
    "    X_train.extend(Parallel(n_jobs=nprocs)(delayed(process_image)(im_file) for im_file in files))\n",
    "    Y_train.extend([j]*len(files))\n",
    "    \n",
    "end = time.time() - start\n",
    "print(\"Time: %.2f seconds\" % end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4327, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "X_train= np.array(X_train)\n",
    "#Y_train = np.array(Y_train)\n",
    "#X_train=[]\n",
    "#Y_train = []\n",
    "print  X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##saving data as h5 file\n",
    "import sys\n",
    "sys.path.append('/home/mohammad/anaconda/lib/python2.7/site-packages')\n",
    "import h5py\n",
    "with h5py.File('/home/mohammad/data3.h5', 'w') as hf:\n",
    "    hf.create_dataset('dataset_1', data=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4663, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/mohammad/anaconda/lib/python2.7/site-packages')\n",
    "import h5py\n",
    "\n",
    "with h5py.File('/home/mohammad/data1.h5','r') as hf:\n",
    "    data = hf.get('dataset_1')\n",
    "    data = np.array(data)\n",
    "    \n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5757f8fcb8b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/mohammad/img_data_vgg_p1.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f = open('/home/mohammad/img_data_vgg_p1.p', 'wb')   \n",
    "pickle.dump(x, f)          \n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('/home/mohammad/img_label_rgb.p', 'wb')  \n",
    "pickle.dump(y, f)          # dump data to f\n",
    "f.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
