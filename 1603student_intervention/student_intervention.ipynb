{"nbformat_minor": 0, "cells": [{"source": "# Project 2: Supervised Learning\n### Building a Student Intervention System", "cell_type": "markdown", "metadata": {}}, {"source": "## 1. Classification vs Regression\n\nYour goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?\n\nAns: In this assignment, we have to predict whether a student will 'pass' or 'fail' from a given set of features.  This is a classification problem because we have to classify students into distinct classes. If it is a regression problem, we have to predict continuous output. Therefore it could be a regression problem if we want to predict the score of final exam.", "cell_type": "markdown", "metadata": {}}, {"source": "## 2. Exploring the Data\n\nLet's go ahead and read in the student dataset first.\n\n_To execute a code cell, click inside it and press **Shift+Enter**._", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "# Import libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.cross_validation import StratifiedShuffleSplit\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 3, "cell_type": "code", "source": "# Read student data\nstudent_data = pd.read_csv(\"C:/Users/Mohammad/git/nanodegree/1603student_intervention/student-data.csv\")\nprint \"Student data read successfully!\"\n# Note: The last column 'passed' is the target/label, all other are feature columns\n", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Student data read successfully!\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"source": "Now, can you find out the following facts about the dataset?\n- Total number of students\n- Number of students who passed\n- Number of students who failed\n- Graduation rate of the class (%)\n- Number of features\n\n_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._", "cell_type": "markdown", "metadata": {}}, {"execution_count": 5, "cell_type": "code", "source": "#student_data.describe()\n#student_data.shape[0]\n#print len(student_data)\nx = student_data.passed.value_counts()\nx['yes']\n#student_data.head(1)\n", "outputs": [{"execution_count": 5, "output_type": "execute_result", "data": {"text/plain": "265"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 6, "cell_type": "code", "source": "# TODO: Compute desired values - replace each '?' with an appropriate expression/function call\nn_students = student_data.shape[0]\nn_features = student_data.shape[1]\n\nx = student_data.passed.value_counts()\n\nn_passed = x['yes']\nn_failed = x['no']\ngrad_rate = 100*float(n_passed)/float(n_students)\nprint \"Total number of students: {}\".format(n_students)\nprint \"Number of students who passed: {}\".format(n_passed)\nprint \"Number of students who failed: {}\".format(n_failed)\nprint \"Number of features: {}\".format(n_features)\nprint \"Graduation rate of the class: {:.2f}%\".format(grad_rate)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Total number of students: 395\nNumber of students who passed: 265\nNumber of students who failed: 130\nNumber of features: 31\nGraduation rate of the class: 67.09%\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"source": "## 3. Preparing the Data\nIn this section, we will prepare the data for modeling, training and testing.\n\n### Identify feature and target columns\nIt is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n\nLet's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\n**Note**: For this dataset, the last column (`'passed'`) is the target or label we are trying to predict.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 7, "cell_type": "code", "source": "# Extract feature (X) and target (y) columns\nfeature_cols = list(student_data.columns[:-1])  # all columns but last are features\ntarget_col = student_data.columns[-1]  # last column is the target/label\nprint \"Feature column(s):-\\n{}\".format(feature_cols)\nprint \"Target column: {}\".format(target_col)\n\nX_all = student_data[feature_cols]  # feature values for all students\ny_all = student_data[target_col]  # corresponding targets/labels\nprint \"\\nFeature values:-\"\nprint X_all.head()  # print the first 5 rows\nprint y_all.describe()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Feature column(s):-\n['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\nTarget column: passed\n\nFeature values:-\n  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n1     GP   F   17       U     GT3       T     1     1  at_home     other   \n2     GP   F   15       U     LE3       T     1     1  at_home     other   \n3     GP   F   15       U     GT3       T     4     2   health  services   \n4     GP   F   16       U     GT3       T     3     3    other     other   \n\n    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n0   ...       yes       no        no       4         3     4    1    1      3   \n1   ...       yes      yes        no       5         3     3    1    1      3   \n2   ...       yes      yes        no       4         3     2    2    3      3   \n3   ...       yes      yes       yes       3         2     2    1    1      5   \n4   ...       yes       no        no       4         3     2    1    2      5   \n\n  absences  \n0        6  \n1        4  \n2       10  \n3        2  \n4        4  \n\n[5 rows x 30 columns]\ncount     395\nunique      2\ntop       yes\nfreq      265\nName: passed, dtype: object\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"source": "### Preprocess feature columns\n\nAs you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\n\nOther columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n\nThese generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": "# Preprocess feature columns\ndef preprocess_features(X):\n    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n\n    # Check each column\n    for col, col_data in X.iteritems():\n        # If data type is non-numeric, try to replace all yes/no values with 1/0\n        if col_data.dtype == object:\n            col_data = col_data.replace(['yes', 'no'], [1, 0])\n        # Note: This should change the data type for yes/no columns to int\n\n        # If still non-numeric, convert to one or more dummy variables\n        if col_data.dtype == object:\n            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n\n        outX = outX.join(col_data)  # collect column(s) in output dataframe\n\n    return outX\n\nX_all = preprocess_features(X_all)\nprint \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Processed feature columns (48):-\n['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"source": "### Split data into training and test sets\n\nSo far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 10, "cell_type": "code", "source": "# First, decide how many training vs test samples you want\nnum_all = student_data.shape[0]  # same as len(student_data)\nnum_train = 300  # about 75% of the data\nnum_test = num_all - num_train\n\n# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n#student_data['passed'] = format(student_data['passed'])\ny = student_data['passed']\n\ndef shuffle_split_data(X,y,num_train):\n    s = StratifiedShuffleSplit(y, 1, train_size=num_train)\n\n    # only one iteration\n    for train_index, test_index in s:\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        \n    return X_train, X_test, y_train, y_test\n    \nX_train, X_test, y_train, y_test = shuffle_split_data(X_all, y,num_train )\n    \nprint \"Training set: {} samples\".format(X_train.shape[0])\nprint \"Test set: {} samples\".format(X_test.shape[0])\n# Note: If you need a validation set, extract it from within training data\n", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Training set: 300 samples\nTest set: 40 samples\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"source": "\n## 4. Training and Evaluating Models\nChoose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\n\n- What is the theoretical O(n) time & space complexity in terms of input size?\n- What are the general applications of this model? What are its strengths and weaknesses?\n- Given what you know about the data so far, why did you choose this model to apply?\n- Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.\n\nProduce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\n\nNote: You need to produce 3 such tables - one for each model.\n\n###Ans:\n\nData characteristics: The dataset contains data from 395 students. Every student data contain 31 features. Target label 'Passed' contains categorical variable: 'yes' and 'no'. Among the students, 265 passed and 135 failed. Graduation rate of the class is around 67.09%. \n\nThere are several issues with the dataset.\n- The number of features is pretty large compare to number of students. In order to classify accurately, the number of training instances needed to increase exponentially as the number of features increase. Therefore, the prediction model will suffer from the curse of dimensionality [1] and the prediction/classification might be overfitted.\n\n- The number students passed and failed are not equal. Some models might be performed poorly under this imbalanced condition. Furthermore, when we just simply split data into test and training sets, there are possibilities when the training set might contain very failed student data and as a result, the prediction model will perform poorly.\nIn order overcome this issue, we applied Stratified Shuffle Split from scikit-learn. Stratified shuffle split ensures the constant ratio of passed and failed students in test and training datasets.\n\n\n\nAccuracy measurement: Accuracy of this prediction model is measured by F1 score. F1 score takes into account both precision and recall scores. \n\n\nFor this problem, we choose Random Forest, Naive Bayes and Support vector machine classifier.\n\nRandom forest classifier is an ensemble learning method that operates by constructing a number of decision tress on various sub-sample of input dataset and use average of the prediction as the final prediction output.\nStrengths:\n1.\tRandom forest can deal with unbalanced data.\n2.\tRuns efficiently on large dataset with numerous number of input features\n3.\tRobust against outliers.\n4.\tDo not overfit like decision tress.\n\nWeakness:\n1.\tThe process is very computation intensive.\n2.\tUsually require large dataset.\n3.\tProne to overfitting when it is applied outside the range of training dataset.\n\nWhy random forest?\nAlthough the dataset is small, I decided to apply Random Forest for following reasons:\n1.\tTo check Random Forest classifier\u2019s performance on small datasets with large number of features.\n2.\tTo check whether a computation intensive Random Forest classifier is a viable option against other simple classifier under given budget constraints.\n\nNaive Bayes Classifier\nThe Naive Bayesian classifier is based on Bayes\u2019 theorem with na\u00efve assumptions of independence between the features. \nStrengths:\n1.\tExtremely fast even with very large dataset.\n2.\tCan work with small dataset.\n3.\tEasy to implement.\n4.\tRobust to noise\n\nWeakness:\n1.\tIn practice, na\u00efve assumptions of independence between the features is very rare.\n2.\tShows poor performance in case of nonlinear classification problems.\n\nWhy Naive Bayes:\n1.\tSmall dataset\n2.\tCompare the performance between simple solution to computational intensive solution\n\nSupport vector machine (SVM) classifier\nSVM classifier is a non-probabilistic parametric based classifier for supervised learning.  It constructs linear hyperplane or set of hyperplanes for separating data points. Linear hyperplanes are used through the kernels for nonlinear classification problems.\nStrengths:\n1.\tHigh accuracy.\n2.\tWorks well with unbalanced data.\n3.\tDo not suffer from multicollinearity.\n\nWeakness:\n1.\tTime consuming process\n2.\tPicking/finding the right kernel can be a challenge\n\nWhy SVM:\nSVM is chosen because:\n1. SVM can produce highly accurate result with unbalanced small data.\n2. Compare the performance of SVM with computation intensive Random Forest classifier and simple Naive Baayes. Find a balance between accuracy and expense of computation.\n \n\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": 46, "cell_type": "code", "source": "# Train a model\nimport time\n\ndef train_classifier(clf, X_train, y_train):\n    print \"Training {}...\".format(clf.__class__.__name__)\n    start = time.time()\n    clf.fit(X_train, y_train)\n    end = time.time()\n    print \"Done!\\nTraining time (secs): {:.3f}\".format(end - start)\n    return end-start\n\n# TODO: Choose a model, import it and instantiate an object\nfrom sklearn.svm import SVC\nsvc_clf = SVC(kernel='rbf')\n\n# Fit model to training data\ntrain_classifier(svc_clf, X_train, y_train)  # note: using entire training set here\n#print clf  # you can inspect the learned model by printing it", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Training SVC...\nDone!\nTraining time (secs): 0.005\n"}, {"execution_count": 46, "output_type": "execute_result", "data": {"text/plain": "0.004999876022338867"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 12, "cell_type": "code", "source": "# Predict on training set and compute F1 score\nfrom sklearn.metrics import f1_score\n\ndef predict_labels(clf, features, target):\n    print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n    start = time.time()\n    y_pred = clf.predict(features)\n    end = time.time()\n    print \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start)\n    return f1_score(target.values, y_pred, pos_label='yes'), end-start\n\ntrain_f1_score,train_time = predict_labels(svc_clf, X_train, y_train)\nprint \"F1 score for training set: {}\".format(train_f1_score)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Predicting labels using SVC...\nDone!\nPrediction time (secs): 0.016\nF1 score for training set: 0.863930885529\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 13, "cell_type": "code", "source": "# Predict on test data\ntest_f1_score,test_time = predict_labels(svc_clf, X_test, y_test)\nprint \"F1 score for test set: {}\".format(test_f1_score)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Predicting labels using SVC...\nDone!\nPrediction time (secs): 0.004\nF1 score for test set: 0.825396825397\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 14, "cell_type": "code", "source": "# Train and predict using different training set sizes\ndef train_predict(clf, X_train, y_train, X_test, y_test):\n    print \"------------------------------------------\"\n    print \"Training set size: {}\".format(len(X_train))\n    x=train_classifier(clf, X_train, y_train)\n    f1_score_train,train_time= predict_labels(clf, X_train, y_train)\n    print \"F1 score for training set: {}\".format(f1_score_train)\n    f1_score_test,test_time= predict_labels(clf, X_test, y_test)\n    print \"F1 score for training set: {}\".format(f1_score_test)\n    return (f1_score_train, f1_score_test, x,test_time)\n\n# TODO: Run the helper function above for desired subsets of training data\n# Note: Keep the test set constant", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 15, "cell_type": "code", "source": "# TODO: Train and predict using two other models\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier(n_estimators=200)\n\n# Fit model to training data\n#train_classifier(rf_clf, X_train, y_train)  # note: using entire training set here\n#print rf_clf\ntrain_predict(rf_clf, X_train, y_train, X_test, y_test)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "------------------------------------------\nTraining set size: 300\nTraining RandomForestClassifier...\nDone!\nTraining time (secs): 0.228\nPredicting labels using RandomForestClassifier...\nDone!\nPrediction time (secs): 0.047\nF1 score for training set: 1.0\nPredicting labels using RandomForestClassifier...\nDone!\nPrediction time (secs): 0.016\nF1 score for training set: 0.838709677419\n"}, {"execution_count": 15, "output_type": "execute_result", "data": {"text/plain": "(1.0, 0.83870967741935487, 0.22799992561340332, 0.016000032424926758)"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 16, "cell_type": "code", "source": "from sklearn.naive_bayes import MultinomialNB\nnb_clf = MultinomialNB(alpha=30)\nprint nb_clf\ntrain_predict(nb_clf, X_train, y_train, X_test, y_test)\n", "outputs": [{"output_type": "stream", "name": "stdout", "text": "MultinomialNB(alpha=30, class_prior=None, fit_prior=True)\n------------------------------------------\nTraining set size: 300\nTraining MultinomialNB...\nDone!\nTraining time (secs): 0.320\nPredicting labels using MultinomialNB...\nDone!\nPrediction time (secs): 0.017\nF1 score for training set: 0.817610062893\nPredicting labels using MultinomialNB...\nDone!\nPrediction time (secs): 0.016\nF1 score for training set: 0.857142857143\n"}, {"execution_count": 16, "output_type": "execute_result", "data": {"text/plain": "(0.81761006289308169,\n 0.8571428571428571,\n 0.31999993324279785,\n 0.016000032424926758)"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 17, "cell_type": "code", "source": "\n#X_train\n#train_predict(nb_clf, x1, y1, X_test, y_test)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 47, "cell_type": "code", "source": "### Run the helper function above for desired subsets of training data\n# Note: Keep the test set constant\n\ndef compare_algorithm(algorithm, size):\n    for i in algorithm:\n        training_time = []\n        prediction_time = []\n        f1_train_score = []\n        f1_test_score = []\n        z = ['train_size','train_time','f1_train','test_time','f1_test']\n        for j in size:\n            x1,x2,y1,y2 = shuffle_split_data(X_all, y,j )\n            total_f1_train_score,total_f1_test_score,total_training_time, total_prediction_time  =train_predict(i, x1, y1, X_test, y_test)\n            training_time.append(total_training_time)\n            prediction_time.append(total_prediction_time)\n            f1_train_score.append(total_f1_train_score)\n            f1_test_score.append(total_f1_test_score)\n            \n        tab= [size,training_time,f1_train_score,prediction_time,f1_test_score]\n        tab = pd.DataFrame(tab)\n        tab[' ']=z\n        tab = tab[[' ',0,1,2]]\n        print \"------------------------------------------\"\n        print \"Summary Table\"\n        print \"------------------------------------------\"\n        print tab\n            \ncompare_algorithm([nb_clf,rf_clf,svc_clf],[100,200,300])\n", "outputs": [{"output_type": "stream", "name": "stdout", "text": "------------------------------------------\nTraining set size: 100\nTraining MultinomialNB...\nDone!\nTraining time (secs): 0.000\nPredicting labels using MultinomialNB...\nDone!\nPrediction time (secs): 0.000\nF1 score for training set: 0.802395209581\nPredicting labels using MultinomialNB...\nDone!\nPrediction time (secs): 0.000\nF1 score for training set: 0.805970149254\n------------------------------------------\nTraining set size: 200\nTraining MultinomialNB...\nDone!\nTraining time (secs): 0.000\nPredicting labels using MultinomialNB...\nDone!\nPrediction time (secs): 0.000\nF1 score for training set: 0.806060606061\nPredicting labels using MultinomialNB...\nDone!\nPrediction time (secs): 0.000\nF1 score for training set: 0.805970149254\n------------------------------------------\nTraining set size: 300\nTraining MultinomialNB...\nDone!\nTraining time (secs): 0.000\nPredicting labels using MultinomialNB...\nDone!\nPrediction time (secs): 0.000\nF1 score for training set: 0.803347280335\nPredicting labels using MultinomialNB...\nDone!\nPrediction time (secs): 0.000\nF1 score for training set: 0.830769230769\n------------------------------------------\nSummary Table\n------------------------------------------\n                        0           1           2\n0  train_size  100.000000  200.000000  300.000000\n1  train_time    0.000000    0.000000    0.000000\n2    f1_train    0.802395    0.806061    0.803347\n3   test_time    0.000000    0.000000    0.000000\n4     f1_test    0.805970    0.805970    0.830769\n------------------------------------------\nTraining set size: 100\nTraining RandomForestClassifier...\nDone!\nTraining time (secs): 0.158\nPredicting labels using RandomForestClassifier...\nDone!\nPrediction time (secs): 0.012\nF1 score for training set: 1.0\nPredicting labels using RandomForestClassifier...\nDone!\nPrediction time (secs): 0.015\nF1 score for training set: 0.885245901639\n------------------------------------------\nTraining set size: 200\nTraining RandomForestClassifier...\nDone!\nTraining time (secs): 0.147\nPredicting labels using RandomForestClassifier...\nDone!\nPrediction time (secs): 0.016\nF1 score for training set: 1.0\nPredicting labels using RandomForestClassifier...\nDone!\nPrediction time (secs): 0.019\nF1 score for training set: 0.9\n------------------------------------------\nTraining set size: 300\nTraining RandomForestClassifier...\nDone!\nTraining time (secs): 0.132\nPredicting labels using RandomForestClassifier...\nDone!\nPrediction time (secs): 0.018\nF1 score for training set: 1.0\nPredicting labels using RandomForestClassifier...\nDone!\nPrediction time (secs): 0.010\nF1 score for training set: 0.947368421053\n------------------------------------------\nSummary Table\n------------------------------------------\n                        0        1           2\n0  train_size  100.000000  200.000  300.000000\n1  train_time    0.158000    0.147    0.132000\n2    f1_train    1.000000    1.000    1.000000\n3   test_time    0.015000    0.019    0.010000\n4     f1_test    0.885246    0.900    0.947368\n------------------------------------------\nTraining set size: 100\nTraining SVC...\nDone!\nTraining time (secs): 0.001\nPredicting labels using SVC...\nDone!\nPrediction time (secs): 0.001\nF1 score for training set: 0.91156462585\nPredicting labels using SVC...\nDone!\nPrediction time (secs): 0.000\nF1 score for training set: 0.754098360656\n------------------------------------------\nTraining set size: 200\nTraining SVC...\nDone!\nTraining time (secs): 0.003\nPredicting labels using SVC...\nDone!\nPrediction time (secs): 0.002\nF1 score for training set: 0.864516129032\nPredicting labels using SVC...\nDone!\nPrediction time (secs): 0.000\nF1 score for training set: 0.857142857143\n------------------------------------------\nTraining set size: 300\nTraining SVC...\nDone!\nTraining time (secs): 0.007\nPredicting labels using SVC...\nDone!\nPrediction time (secs): 0.005\nF1 score for training set: 0.854700854701\nPredicting labels using SVC...\nDone!\nPrediction time (secs): 0.001\nF1 score for training set: 0.870967741935\n------------------------------------------\nSummary Table\n------------------------------------------\n                        0           1           2\n0  train_size  100.000000  200.000000  300.000000\n1  train_time    0.001000    0.003000    0.007000\n2    f1_train    0.911565    0.864516    0.854701\n3   test_time    0.000000    0.000000    0.001000\n4     f1_test    0.754098    0.857143    0.870968\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"source": "## 5. Choosing the Best Model\n\n- Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n\nFrom the experiments, we can conclude that all three models (Naive Bayes, Random Forest and SVM) performed reasonably well. F1 score shows that the Random forest classifiers is the most accurate and Naive Bayes is the least accurate. However, from time comparison, Random forest classifiers required most time to train models. In contrast of Naive Bayes and Random Forest, SVM classifer produces very good accuracy (f1_test=0.870) with very small training time. Therefore, I think SVM will be the best one for this problem based on the available data, limited resources and budget constraints.\n\n\n- In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n\n\nSVM is a linear classification technique which assume that your data are linearly separable[1].  In layman's terms, it involves finding the hyperplane that best separates two classes of points with the maximum margin. Essentially, it is a constrained optimization problem where the margin is maximized subject to the constraint. Maximizedd margin makes the probability of missclassifying test data lower.\n\nFor example lets consider a 2-D case, where we have to classify points distributed in x-y plane. In order to classify points, SVM will search for an optimum hyperplane (i.e. a line for a 2-D problem) that seperates the instances by a maximum margin. For 3-D problem, SVM will search for plane; and for higher dimensional problems, SVM will search for hyperplane higher dimension.\n\nSince we are dealing with a multidimensional problem, SVM will try to find the hpyperplane that maximizes the differences between graduated and non-graduated students.\n\n- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n\n- What is the model's final F<sub>1</sub> score?\n\nAfter a thorough grid-search, final F<sub>1</sub> score is 0.871, which is very small improvement over the previous model.\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": 43, "cell_type": "code", "source": "# TODO: Fine-tune your model and report the best F1 score\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.svm import SVC\nsvc_clf = SVC()\n\nparameters = {'kernel': ['linear','rbf'], 'C': (0.01,0.05,0.15,0.25,0.35,0.45,0.50,0.75,1,2),\n              'gamma':(0,0.001,0.01,0.02,0.1,0.5,0.75)}\nf1_scorer = make_scorer(f1_score, pos_label=\"yes\")\n\nclf = GridSearchCV(svc_clf, parameters, scoring = f1_scorer)\n\nclf.fit(X_train, y_train)\n", "outputs": [{"execution_count": 43, "output_type": "execute_result", "data": {"text/plain": "GridSearchCV(cv=None, error_score='raise',\n       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False),\n       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n       param_grid={'kernel': ['linear', 'rbf'], 'C': (0.01, 0.05, 0.15, 0.25, 0.35, 0.45, 0.5, 0.75, 1, 2), 'gamma': (0, 0.001, 0.01, 0.02, 0.1, 0.5, 0.75)},\n       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n       scoring=make_scorer(f1_score, pos_label=yes), verbose=0)"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 48, "cell_type": "code", "source": "best_F1_score = '{0:.3f}'.format(f1_score(clf.predict(X_test), y_test, pos_label='yes'))\n\nprint \"Best F1 Score: \" +  best_F1_score\nprint \"\\nBest model parameter:  \" + str( clf.best_params_)\nprint \"\\nBest estimator:\\n{}\".format(clf.best_estimator_)\n", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Best F1 Score: 0.871\n\nBest model parameter:  {'kernel': 'linear', 'C': 0.05, 'gamma': 0}\n\nBest estimator:\nSVC(C=0.05, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0,\n  kernel='linear', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False)\n(300, 48)\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"source": "", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}